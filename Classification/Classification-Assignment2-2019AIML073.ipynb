{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Na√Øve Bayes and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Question 1***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iris Dataset Keys:\n",
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "\n",
      "Class Labels are:\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "3 class labels\n",
      "(150, 4)\n",
      "(150,)\n",
      "\n",
      "X values will be extracted as:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "\n",
      "Y values will be extracted as:\n",
      "            0\n",
      "0      setosa\n",
      "1  versicolor\n",
      "2   virginica\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Now we load the Iris DataSet in a variable called \"iris\"\n",
    "iris = load_iris()\n",
    "\n",
    "# inpsect iris_dataset keys\n",
    "print ()\n",
    "print (\"Iris Dataset Keys:\")\n",
    "print (iris.keys())\n",
    "\n",
    "# X is original data, Rows are individual samples, colums are features\n",
    "X = iris.data\n",
    "\n",
    "# class lable (integer)\n",
    "# corresponds to index of row of X\n",
    "y = iris.target\n",
    "\n",
    "# inspect target names\n",
    "print ()\n",
    "print (\"Class Labels are:\")\n",
    "print (iris.target_names)\n",
    "\n",
    "# number of class labels\n",
    "Cn = len(iris.target_names)\n",
    "print (\"{} class labels\".format(Cn))\n",
    "\n",
    "print (X.shape)\n",
    "print (y.shape)\n",
    "\n",
    "x2 = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "y2 = pd.DataFrame(iris.target_names)\n",
    "x1 = x2.head()\n",
    "y1 = y2.head()\n",
    "print ()\n",
    "print (\"X values will be extracted as:\")\n",
    "print (x1)\n",
    "\n",
    "print()\n",
    "print(\"Y values will be extracted as:\")\n",
    "print (y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 1.2 and 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.80      1.00      0.89        12\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "\n",
      "accuracy score as per classification report from sklearn metrics is:\n",
      "0.9333333333333333\n",
      "\n",
      "Confusion matrix as derived from sklearn metrics is:\n",
      "[[15  0  0]\n",
      " [ 0 15  3]\n",
      " [ 0  0 12]]\n",
      "Correct predictions:  42\n",
      "False predictions 3\n",
      "\n",
      "\n",
      "Accuracy of the Naive Bayes Clasification is:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=6)\n",
    "      \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gb = GaussianNB()\n",
    "      \n",
    "gb.fit(X_train,y_train)\n",
    "      \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = nv.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_pred,y_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))\n",
    "\n",
    "print()\n",
    "print(\"accuracy score as per classification report from sklearn metrics is:\")\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "\n",
    "print()\n",
    "print(\"Confusion matrix as derived from sklearn metrics is:\")\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "\n",
    "\n",
    "# Now we will validate our results by calculating correct predictions and false predictions\n",
    "\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "a = conf.shape\n",
    "corrPred = 0\n",
    "falsePred = 0\n",
    "\n",
    "for row in range(a[0]):\n",
    "    for c in range(a[1]):\n",
    "        if row == c:\n",
    "            corrPred +=conf[row,c]\n",
    "        else:\n",
    "            falsePred += conf[row,c]\n",
    "print('Correct predictions: ', corrPred)\n",
    "print('False predictions', falsePred)\n",
    "print ('\\n\\nAccuracy of the Naive Bayes Clasification is: ', corrPred/(conf.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the 3x3 confusion matrix in our case, the columns are the predictions and the rows must therefore be the actual values. The main diagonal (15, 15, 12) gives the correct predictions. That is, the cases where the actual values and the model predictions are the same and rest are false predictions.\n",
    "\n",
    "#### Accuracy is defined by \"Correct Predictions/Total Predictions\" and hence our accuracy is coming out to be 93.3334%\n",
    "\n",
    "\n",
    "### Now we will do some predictions as shown below, which proves the accuracy of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['setosa' 'virginica' 'setosa' 'setosa' 'virginica' 'versicolor'\n",
      " 'versicolor' 'setosa' 'virginica' 'versicolor' 'virginica' 'versicolor'\n",
      " 'virginica' 'virginica' 'versicolor' 'versicolor' 'virginica'\n",
      " 'versicolor' 'versicolor' 'setosa' 'setosa' 'virginica' 'setosa' 'setosa'\n",
      " 'versicolor' 'versicolor' 'versicolor' 'virginica' 'setosa' 'versicolor'\n",
      " 'setosa' 'versicolor' 'setosa' 'setosa' 'versicolor' 'virginica'\n",
      " 'versicolor' 'virginica' 'versicolor' 'setosa' 'setosa' 'virginica'\n",
      " 'versicolor' 'versicolor' 'setosa']\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "print()\n",
    "z_pred = nv.predict(X_test)\n",
    "print (iris.target_names[z_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Question 2***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 2.1 and 2.2\n",
    "\n",
    "### Objective: We have to import the car.data dataset from https://archive.ics.uci.edu/ml/machine-learning-databases/car/ and extract X as all columns except the last column and Y as last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the Data: \", data.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning names to the columns in the dataset\n",
    "\n",
    "data.columns = ['Price', 'Maintenance Cost', 'Number of Doors', 'Capacity', 'Size of Luggage Boot', 'safety', 'Decision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will extract X as all columns except the last column and Y as last column as represented below\n",
    "# We will validate their shapes and print the values of X and y for our reference in next cell.\n",
    "\n",
    "# X is the dataframe containing input data / features\n",
    "# y is the series which has results which are to be predicted.\n",
    "\n",
    "X=data[data.columns[:-1]]\n",
    "\n",
    "y=data['Decision']\n",
    "\n",
    "print(\"Shape of X: \", X.shape)\n",
    "print(\"Shape of y: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will perform EDA to analyze the data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get info of dataset and check for null values if any\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Decision'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As all the columns are categorical, check for unique values of each column\n",
    "\n",
    "for i in data.columns:\n",
    "    print(data[i].unique(),\"\\t\",data[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will check how these unique categories are distributed among the columns\n",
    "for i in data.columns:\n",
    "    print(data[i].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above output, it is clear that all the columns except 'Decision' are distributed equally among data.\n",
    "\n",
    "#Below is the graph which gives the count of unique values in column.\n",
    "\n",
    "sns.countplot(data['Decision'])\n",
    "\n",
    "# It can be seen from the graph that the result 'class' is unbalanced with larger values of 'unacc'.\n",
    "# So, this is an unbalanced multiclass classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As scikit-learn algorithms do not generally work with string values,\n",
    "# I've converted string categories to integers.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    data[i]=le.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will get Heatmap of the columns on dataset with each other.\n",
    "# It shows Pearson's correlation coefficient of column w.r.t other columns. \n",
    "fig=plt.figure(figsize=(10,6))\n",
    "sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignoring the diagonal values, it can be seen that most of the columns shows very weak correlation with 'Decison'.\n",
    "#### 'persons' column is showning a weak relation with 'Decision'. Other columns except 'Decision' shows no correlation with each other.\n",
    "\n",
    "#### So, plotting these columns with each other or doing any analysis on them may not give any productive output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer 2.3, 2.4 and 2.5\n",
    "\n",
    "### Objective 2.3 - Split the data into training set and testing set. Perform 10-fold cross validation.\n",
    "### Objective 2.4 - Train a Logistic regression model for the dataset and explain the parameters of model. \n",
    "### Objective 2.5 - Compute the accuracy and confusion matrix. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data in train and test sets\n",
    "\n",
    "\n",
    "X=data[data.columns[:-1]]\n",
    "\n",
    "y=data['Decision']\n",
    "\n",
    "print(\"Shape of X: \", X.shape)\n",
    "print(\"Shape of y: \", y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Shape of x_train: \", X_train.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"shape of x_test: \", X_test.shape)\n",
    "print(\"shape of y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(solver='newton-cg',multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracy: \",logreg.score(X_train, y_train))\n",
    "print(\"Testing Accuracy: \", logreg.score(X_test, y_test))\n",
    "\n",
    "# predicting the values for x-test\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# printing the confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, basic logistic regression model is giving very less accuracy. Let's check the learning curves\n",
    "\n",
    "from sklearn.model_selection import learning_curve,cross_val_score,validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc=learning_curve(logreg,X_train,y_train,cv=10,n_jobs=-1)\n",
    "size=lc[0]\n",
    "train_score=[lc[1][i].mean() for i in range (0,5)]\n",
    "test_score=[lc[2][i].mean() for i in range (0,5)]\n",
    "fig=plt.figure(figsize=(12,8))\n",
    "plt.plot(size,train_score)\n",
    "plt.plot(size,test_score)\n",
    "\n",
    "# From above graph, with the increasing number of samples, train accuracy is decreasing.\n",
    "\n",
    "# Let's modify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve,cross_val_score,validation_curve\n",
    "param_range=[0.0001,0.001,0.1,1]\n",
    "curve=validation_curve(logreg,X_train,y_train,cv=5,param_name='C',\n",
    "    param_range=param_range,n_jobs=-1,)\n",
    "\n",
    "n=len(param_range)\n",
    "train_score=[curve[0][i].mean() for i in range (0,n)]\n",
    "test_score=[curve[1][i].mean() for i in range (0,n)]\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "plt.plot(param_range,train_score)\n",
    "plt.plot(param_range,test_score)\n",
    "plt.xticks=param_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It clear that C=0.1 is giving a good result.\n",
    "\n",
    "#### Now, as it is a multiclass classification, I tired using 'newton-cg','sag','lgfbs' solvers.\n",
    "\n",
    "#### As this dataset is smaller, we can use GridSearch to get best possible parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As directed in question, we will use 10-fold cross validation\n",
    "\n",
    "param_grid={'C':[0.01,0.1,1,10],\n",
    "           'solver':['newton-cg', 'lbfgs', 'sag'],\n",
    "           'multi_class':['multinomial']}\n",
    "grid=GridSearchCV(estimator=LogisticRegression(n_jobs=-1),param_grid=param_grid,cv=10,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, with the above parameters, we can get at accuracy of 71%.\n",
    "\n",
    "#### As it is an unbalanced classification problem, accuracy can't be a good criterion for evaluation. Hence we can stay put with this accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we check overall scores of the entire data set\n",
    "\n",
    "data.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
