{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering\n",
    "\n",
    "Clustering is an interesting field of Unsupervised Machine learning where we classify \n",
    "datasets into set of similar groups. It is part of ‘Unsupervised learning’ meaning, where\n",
    "there is no prior training happening and the dataset will be unlabeled. Clustering can be\n",
    "done using different techniques like K-means clustering, Mean Shift clustering, DB Scan \n",
    "clustering, Hierarchical clustering etc. \n",
    "\n",
    "Image clustering\n",
    "\n",
    "\n",
    "Image clustering is an essential data analysis tool in machine\n",
    "learning and computer vision. Many applications\n",
    "such as content-based image annotation and\n",
    "image retrieval can be viewed as different instances\n",
    "of image clustering. Technically, image clustering\n",
    "is the process of grouping images into clusters such that the\n",
    "images within the same clusters are similar to each other,\n",
    "while those in different clusters are dissimilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.cluster import KMeans   # import Kmeans from sklearn\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3661: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:168: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:175: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "(1, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16        # import VGG from keras application as VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)    \n",
    "\n",
    "img_path = '/home/chinesh/Desktop/tapchief/bits/dataset/_83930440_lion-think-976.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224)) \n",
    "img_data = image.img_to_array(img)\n",
    "img_data = np.expand_dims(img_data, axis=0)\n",
    "img_data = preprocess_input(img_data)\n",
    "\n",
    "vgg16_feature = model.predict(img_data)  \n",
    "\n",
    "print(vgg16_feature.shape)  # print the shape of the feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " VGG is a convolutional neural network model for image recognition proposed by the Visual Geometry Group in the University of Oxford, where VGG16 refers to a VGG model with 16 weight layers, and VGG19 refers to a VGG model with 19 weight layers. The architecture of VGG16: the input layer takes an image in the size of (224 x 224 x 3), and the output layer is a softmax prediction on 1000 classes. From the input layer to the last max pooling layer (labeled by 7 x 7 x 512) is regarded as the feature extraction part of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(directory):\n",
    "    vgg16_feature_list = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "\n",
    "        img = image.load_img(os.path.join(directory,filename), target_size=(224, 224))\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "\n",
    "        vgg16_feature = model.predict(img_data)\n",
    "        vgg16_feature_np = np.array(vgg16_feature)\n",
    "        vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
    "\n",
    "    vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
    "    \n",
    "    return vgg16_feature_list_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given dataset has three classes that are: Lion , Fish and Zebra, but we are not providing any \n",
    "    supervision to the model i.e. we are not specifying which image is associated with which\n",
    "    class / cluster. For this we using unsupervised image clustering to create the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_vector = extract_feature('/home/chinesh/Desktop/tapchief/bits/final_dataset')  # pass the path of the folder where you have the training dataset\n",
    "number_of_clusters = 3\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=number_of_clusters) # create the kmeans object and initialize it with the number_of_clusters\n",
    "kmeans_model.fit(train_feature_vector) # call fit function on the train_feature_vector \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# create a test vector using extract_feature function. It will return a feature vector of size \n",
    "# number of images * size of the feature vector\n",
    "\n",
    "test_vector  = extract_feature('/home/chinesh/Desktop/tapchief/bits/test_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 25088)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the kmeans model to predict the labels for the test vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans_model.predict(test_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the labels and the images, save the images in the different folders in respective \n",
    "#clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/chinesh/Desktop/tapchief/bits/test_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chinesh/Desktop/tapchief/bits/result/label_1\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_2\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_1\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_1\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_1\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_2\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_2\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_1\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_2\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_1\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_1\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_1\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n",
      "/home/chinesh/Desktop/tapchief/bits/result/label_0\n"
     ]
    }
   ],
   "source": [
    "path = {0:'label_0',  1:'label_1' ,2:'label_2'}\n",
    "save_dir = '/home/chinesh/Desktop/tapchief/bits/result'\n",
    "count = 0\n",
    "for filename in os.listdir(directory):\n",
    "    print(os.path.join(save_dir,path[y_kmeans[count]]))\n",
    "    shutil.copy(os.path.join(directory,filename), os.path.join(save_dir,path[y_kmeans[count]]))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
