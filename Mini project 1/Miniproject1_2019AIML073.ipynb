{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Clustering\n",
    "\n",
    "Clustering is an interesting field of Unsupervised Machine learning where we classify \n",
    "datasets into set of similar groups. It is part of ‘Unsupervised learning’ meaning, where\n",
    "there is no prior training happening and the dataset will be unlabeled. Clustering can be\n",
    "done using different techniques like K-means clustering, Mean Shift clustering, DB Scan \n",
    "clustering, Hierarchical clustering etc. \n",
    "\n",
    "###### Image clustering\n",
    "\n",
    "\n",
    "Image clustering is an essential data analysis tool in machine\n",
    "learning and computer vision. Many applications\n",
    "such as content-based image annotation and\n",
    "image retrieval can be viewed as different instances\n",
    "of image clustering. Technically, image clustering\n",
    "is the process of grouping images into clusters such that the\n",
    "images within the same clusters are similar to each other,\n",
    "while those in different clusters are dissimilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Code: import Kmeans library from sklearn ( 1 point)\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### VGG \n",
    "\n",
    "VGG is a convolutional neural network model for image recognition proposed by the Visual Geometry Group in the University of Oxford, where VGG16 refers to a VGG model with 16 weight layers, and VGG19 refers to a VGG model with 19 weight layers. The architecture of VGG16: the input layer takes an image in the size of (224 x 224 x 3), and the output layer is a softmax prediction on 1000 classes. From the input layer to the last max pooling layer (labeled by 7 x 7 x 512) is regarded as the feature extraction part of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the vgg16 features is : (1, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "# Code: import VGG feature extraction from keras application as VGG16 (1 point)\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)    \n",
    "# Code: Specify path of the random image from the training dataset. (1 point)\n",
    "img_path = \"dataset/train_dataset/_83930440_lion-think-976.jpg\"\n",
    "img = image.load_img(img_path, target_size=(224, 224)) \n",
    "img_data = image.img_to_array(img)\n",
    "img_data = np.expand_dims(img_data, axis=0)\n",
    "\n",
    "vgg16_feature = model.predict(img_data)  \n",
    "\n",
    "# Code: print the shape of the vgg16_feature  (1 point)\n",
    "print('Shape of the vgg16 features is :',vgg16_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The given function will extract the features from the images.\n",
    "def extract_feature(directory):\n",
    "    vgg16_feature_list = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "\n",
    "        img = image.load_img(os.path.join(directory,filename), target_size=(224, 224))\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "\n",
    "        vgg16_feature = model.predict(img_data)\n",
    "        vgg16_feature_np = np.array(vgg16_feature)\n",
    "        vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
    "\n",
    "    vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
    "    \n",
    "    return vgg16_feature_list_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given dataset has three classes that are: Lion , Fish and Zebra, but we are not providing any \n",
    "    supervision to the model i.e. we are not specifying which image is associated with which\n",
    "    class / cluster. For this we using unsupervised image clustering to create the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_vector = extract_feature(\"dataset/train_dataset\")  # pass the path of the folder where you have the training dataset\n",
    "# Code: create the kmeans object and initialize it with the number_of_clusters = 3   (2 point)\n",
    "kmeans_model = KMeans(n_clusters=3)\n",
    "kmeans_model.fit(train_feature_vector) \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test vector using extract_feature function. It will return a feature vector of size \n",
    "# number of images * size of the feature vector\n",
    "\n",
    "test_vector  = extract_feature('dataset/test_dataset')  # (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the test vector is : (32, 25088)\n"
     ]
    }
   ],
   "source": [
    "# Code: print the shape of the test vector   # (1 point)\n",
    "print('Shape of the test vector is :',test_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of labels:  32\n"
     ]
    }
   ],
   "source": [
    "labels = kmeans_model.predict(test_vector)\n",
    "# Code: use the kmeans model to predict the labels for the test vector (1 point)\n",
    "print('Length of labels: ',len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Using the labels and the images, save the test images in the different folders in respective \n",
    "#clusters.   (2 point)\n",
    "#Assuming the label 0 is for fish, label 1 is for zebra and label 2 is for lion\n",
    "from shutil import copyfile\n",
    "len_labels = len(labels)\n",
    "test_folder = \"dataset/test_dataset/\"\n",
    "output_zebra = \"output/zebra/\"\n",
    "output_lion = \"output/lion/\"\n",
    "output_fish = \"output/fish/\"\n",
    "test_file = []\n",
    "for files in os.listdir(test_folder):\n",
    "    if not files.startswith('.DS_Store'):\n",
    "        test_file.append(files)\n",
    "for i in range(len_labels):\n",
    "    if labels[i] == 0:\n",
    "        copyfile(test_folder + test_file[i], output_fish + test_file[i])\n",
    "    elif labels[i] == 1:\n",
    "        copyfile(test_folder + test_file[i], output_zebra + test_file[i])\n",
    "    else:\n",
    "        copyfile(test_folder + test_file[i], output_lion + test_file[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
