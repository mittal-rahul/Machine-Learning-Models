{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)         # Initialize the random number generator.\n",
    "np.random.seed(42)      # With the seed reset, the same set of \n",
    "                        # numbers will appear every time. \n",
    "tf.set_random_seed(42)  # sets the graph-level random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MNIST dataset  of Keras.\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(Xtrain, Ytrain) , (Xtest, Ytest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# size of the datsets\n",
    "\n",
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(Ytrain.shape)\n",
    "print(Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain \n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  24 209 254 254 254\n",
      " 171   0   0   0   0   0   0   0   0   0]\n",
      "Xtest \n",
      " [  0   0   0   0   0   0   0   0 194 254 103   0   0   0   0   0   0   0\n",
      "   0   0 150 254 213   0   0   0   0   0]\n",
      "Ytrain \n",
      " 3\n",
      "Ytest \n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "# print a sample data\n",
    "\n",
    "print('Xtrain \\n', Xtrain[10,10])\n",
    "print('Xtest \\n', Xtest[10,10])\n",
    "print('Ytrain \\n', Ytrain[10,])\n",
    "print('Ytest \\n', Ytest[10,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "# 60000 input images are in the train set.\n",
    "# 10000 input images are in the test set.\n",
    "\n",
    "Xtrain = Xtrain.reshape((60000, 28*28))    # reshape the input set to size 28*28. \n",
    "Xtrain = Xtrain.astype('float32')/255      # normalize to grayscale; set datatype as float32\n",
    "\n",
    "Xtest = Xtest.reshape((10000, 28*28))      # reshape the input set to size 28*28. \n",
    "Xtest = Xtest.astype('float32')/255        # normalize to grayscale; set datatype as float32\n",
    "\n",
    "Ytrain = tf.keras.utils.to_categorical(Ytrain)\n",
    "Ytest = tf.keras.utils.to_categorical(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain \n",
      " 0.0\n",
      "Xtest \n",
      " 0.0\n",
      "Ytrain \n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Ytest \n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# print a sample data\n",
    "\n",
    "print('Xtrain \\n', Xtrain[10,10])\n",
    "print('Xtest \\n', Xtest[10,10])\n",
    "print('Ytrain \\n', Ytrain[10,])\n",
    "print('Ytest \\n', Ytest[10,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Keras, create the DNN or Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model object\n",
    "\n",
    "dnnModel = models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dense layers, specifying the number of units in each layer and the activation function used in the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                3060      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 44,450\n",
      "Trainable params: 44,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Layer 1 = input layer\n",
    "# specify the input size in the first layer.\n",
    "\n",
    "dnnModel.add(layers.Dense(50, activation='relu', input_shape= (28*28,)))\n",
    "\n",
    "# Layer 2 = hidden layer \n",
    "dnnModel.add(layers.Dense(60, activation='relu'))\n",
    "\n",
    "# Layer 3 = hidden layer \n",
    "dnnModel.add(layers.Dense(30, activation='relu'))\n",
    "\n",
    "\n",
    "# Layer 4 = output layer\n",
    "dnnModel.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "dnnModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization and Optimizations of DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure  the model for training, by using appropriate optimizers and regularizations\n",
    "# Available optimizer: adam, rmsprop, adagrad, sgd\n",
    "# loss:  objective that the model will try to minimize. \n",
    "# Available loss: categorical_crossentropy, binary_crossentropy, mean_squared_error\n",
    "# metrics: List of metrics to be evaluated by the model during training and testing. \n",
    "        \n",
    "dnnModel.compile( optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 11s 177us/sample - loss: 0.3533 - acc: 0.8973\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 0.1626 - acc: 0.9519 - loss: 0.1642 - ac\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 9s 151us/sample - loss: 0.1196 - acc: 0.9638\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 16s 260us/sample - loss: 0.0973 - acc: 0.9694\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 11s 183us/sample - loss: 0.0812 - acc: 0.9750\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 9s 145us/sample - loss: 0.0693 - acc: 0.9778s - los\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.0618 - acc: 0.9803\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.0517 - acc: 0.9827\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0471 - acc: 0.9846\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0435 - acc: 0.9860\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.0367 - acc: 0.9878\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0331 - acc: 0.9890s - loss: 0.0329 - acc: 0.9\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0300 - acc: 0.9899\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0283 - acc: 0.9905\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0263 - acc: 0.9909\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0253 - acc: 0.9915\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0216 - acc: 0.9929\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0217 - acc: 0.9928\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 9s 149us/sample - loss: 0.0207 - acc: 0.9929\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.0184 - acc: 0.9941\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.0160 - acc: 0.9945\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.0198 - acc: 0.99341s - l\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.0162 - acc: 0.9944\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0156 - acc: 0.9947\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0180 - acc: 0.9943\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "h  = dnnModel.fit( Xtrain, Ytrain, epochs=25, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training loss \t 0.018042382696829735\n",
      "Final training accuracy  0.99431664\n"
     ]
    }
   ],
   "source": [
    "print('Final training loss \\t', h.history['loss'][-1])\n",
    "print('Final training accuracy ', h.history['acc'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.1351 - acc: 0.9708\n"
     ]
    }
   ],
   "source": [
    "# testing the model\n",
    "\n",
    "testLoss, testAccuracy = dnnModel.evaluate( Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss \t 0.13511005097885523\n",
      "Testing accuracy  0.9708\n"
     ]
    }
   ],
   "source": [
    "print('Testing loss \\t', testLoss)\n",
    "print('Testing accuracy ', testAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise \n",
    "\n",
    "Modify the code to get a better testing accuracy.\n",
    "- Change the number of hidden units\n",
    "- Increase the number of hidden layers\n",
    "- Use a different optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
